apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: mizzou-news-pipeline
  namespace: production
  labels:
    dataset: mizzou-missouri-state
    type: pipeline
spec:
  schedule: "0 */6 * * *"  # Every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
  timezone: "UTC"
  concurrencyPolicy: "Replace"  # Replace running pipeline with new one
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 5
  workflowSpec:
    entrypoint: mizzou-pipeline-wrapper
    serviceAccountName: argo-workflow
    # Add workflow-level metadata for log correlation
    workflowMetadata:
      labels:
        dataset: mizzou-missouri-state
        pipeline-type: scheduled
        schedule: every-6-hours
    
    templates:
    # Wrapper that calls the reusable template
    - name: mizzou-pipeline-wrapper
      steps:
      - - name: run-pipeline
          templateRef:
            name: news-pipeline-template
            template: pipeline
          arguments:
            parameters:
            # Dataset configuration
            - name: dataset
              value: "Mizzou Missouri State"
            - name: source-limit
              value: "10000"
            # Discovery parameters
            # No source-limit = process ALL 157 sources in dataset each run
            - name: max-articles
              value: "50"
            - name: days-back
              value: "7"
            # Verification parameters
            # Larger batch size for efficiency - verification is fast (~100ms per URL)
            # No max-batches limit - process entire backlog every run
            - name: verify-batch-size
              value: "50"
            - name: verify-max-batches
              value: "0"  # Ignored - unlimited batches
            - name: verify-idle-grace-seconds
              value: "3600"  # 1 hour - long enough for discovery to finish
            # Extraction parameters
            # extract-limit: max 3 articles per request (1 domain, below bot threshold)
            # extract-batches: max batches (extract-limit × batches = total capacity)
            # Current: 3 × 667 = ~2,000 articles per run (same capacity)
            # Small batches + randomized domains prevent back-to-back extractions
            - name: extract-limit
              value: "3"
            - name: extract-batches
              value: "667"
            # Moderate rate limiting for Mizzou
            - name: inter-request-min
              value: "5.0"
            - name: inter-request-max
              value: "15.0"
            - name: batch-sleep
              value: "30.0"
            - name: captcha-backoff-base
              value: "1800"    # 30 minutes
            - name: captcha-backoff-max
              value: "7200"    # 2 hours
            # Wait parameters - start extraction when ready
            - name: min-verified
              value: "10"      # Start with just 10 articles ready
            - name: verified-wait-seconds
              value: "120"     # Wait max 2 minutes if threshold not met
