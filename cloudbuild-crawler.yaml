substitutions:
  _BASE_IMAGE: us-central1-docker.pkg.dev/${PROJECT_ID}/mizzou-crawler/base:latest
  _REGISTRY: us-central1-docker.pkg.dev/${PROJECT_ID}/mizzou-crawler
  _RELEASE_VERSION: '1.3.1'

steps:
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '--build-arg'
      - 'BASE_IMAGE=${_BASE_IMAGE}'
      - '-f'
      - 'Dockerfile.crawler'
      - '-t'
      - '${_REGISTRY}/crawler:${SHORT_SHA}'
      - '-t'
      - '${_REGISTRY}/crawler:latest'
      - '-t'
      - '${_REGISTRY}/crawler:v${_RELEASE_VERSION}'
      - '.'
  # Get GKE credentials for kubectl commands
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'get-gke-credentials'
    args:
      - 'container'
      - 'clusters'
      - 'get-credentials'
      - 'mizzou-cluster'
      - '--zone=us-central1-a'

  # Update crawler cronjob to use new image
  - name: 'gcr.io/cloud-builders/kubectl'
    id: 'update-crawler-cronjob'
    env:
      - 'CLOUDSDK_COMPUTE_ZONE=us-central1-a'
      - 'CLOUDSDK_CONTAINER_CLUSTER=mizzou-cluster'
    args:
      - 'set'
      - 'image'
      - 'cronjob/mizzou-crawler'
      - 'crawler=${_REGISTRY}/crawler:${SHORT_SHA}'
      - '--namespace=production'
    waitFor: ['get-gke-credentials']

  # Update discovery cronjob to use new image (if it exists)
  - name: 'gcr.io/cloud-builders/kubectl'
    id: 'update-discovery-cronjob'
    env:
      - 'CLOUDSDK_COMPUTE_ZONE=us-central1-a'
      - 'CLOUDSDK_CONTAINER_CLUSTER=mizzou-cluster'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        if kubectl get cronjob mizzou-discovery -n production &>/dev/null; then
          kubectl set image cronjob/mizzou-discovery \
            discovery=${_REGISTRY}/crawler:${SHORT_SHA} \
            --namespace=production
          echo "✅ Updated mizzou-discovery cronjob"
        else
          echo "ℹ️  mizzou-discovery cronjob not found, skipping"
        fi
    waitFor: ['get-gke-credentials']

images:
  - '${_REGISTRY}/crawler:${SHORT_SHA}'
  - '${_REGISTRY}/crawler:v${_RELEASE_VERSION}'
  - '${_REGISTRY}/crawler:latest'
timeout: 1800s
options:
  machineType: 'N1_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY
  substitutionOption: 'ALLOW_LOOSE'
